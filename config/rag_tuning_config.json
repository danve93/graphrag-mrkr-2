{
  "default_llm_model": "gpt-4o-mini",
  "sections": [
    {
      "key": "retrieval_fusion",
      "label": "Retrieval Fusion",
      "description": "Combine multiple ranked lists (vector, entity, keyword, paths) using Reciprocal Rank Fusion.",
      "llm_override_enabled": false,
      "llm_override_value": null,
      "parameters": [
        {
          "key": "enable_rrf",
          "label": "Enable RRF Fusion",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Use Reciprocal Rank Fusion to robustly combine rankings from vector, entity, keyword (BM25), and path-based retrieval. Recommended for product documentation to balance lexical and semantic matches."
        },
        {
          "key": "rrf_k",
          "label": "RRF k (rank discount)",
          "value": 60,
          "options": null,
          "min": 10.0,
          "max": 200.0,
          "step": 5.0,
          "type": "slider",
          "tooltip": "Controls rank discount in RRF scoring (score = 1/(k + rank)). Higher values flatten differences between ranks, blending lists more evenly. 60 is a common robust default."
        },
        {
          "key": "enable_chunk_fulltext",
          "label": "Enable Keyword (BM25)",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Include Neo4j fulltext/BM25 keyword matches in retrieval. Recommended for product docs where exact terminology matters."
        },
        {
          "key": "keyword_search_weight",
          "label": "Keyword Weight (0-1)",
          "value": 0.3,
          "options": null,
          "min": 0.0,
          "max": 1.0,
          "step": 0.05,
          "type": "slider",
          "tooltip": "Relative weight for keyword matches within hybrid scoring when not using RRF or for downstream blending. Increase to boost exact term matches."
        },
        {
          "key": "hybrid_chunk_weight",
          "label": "Chunk Weight (0-1)",
          "value": 0.6,
          "options": null,
          "min": 0.0,
          "max": 1.0,
          "step": 0.05,
          "type": "slider",
          "tooltip": "Relative weight for vector-similarity chunk results in hybrid retrieval when blending scores."
        },
        {
          "key": "hybrid_entity_weight",
          "label": "Entity Weight (0-1)",
          "value": 0.4,
          "options": null,
          "min": 0.0,
          "max": 1.0,
          "step": 0.05,
          "type": "slider",
          "tooltip": "Relative weight for entity-aware results in hybrid retrieval when blending scores."
        }
      ]
    },
    {
      "key": "reranking",
      "label": "Reranking",
      "description": "Configure FlashRank reranking to refine top candidates.",
      "llm_override_enabled": false,
      "llm_override_value": null,
      "parameters": [
        {
          "key": "flashrank_enabled",
          "label": "Enable FlashRank Reranker",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Enable the FlashRank reranker to refine candidate ordering after fusion."
        },
        {
          "key": "flashrank_model_name",
          "label": "FlashRank Model",
          "value": "ms-marco-TinyBERT-L-2-v2",
          "options": [
            "ms-marco-TinyBERT-L-2-v2",
            "ms-marco-MiniLM-L-12-v2",
            "bge-small-en-v1.5"
          ],
          "min": null,
          "max": null,
          "step": null,
          "type": "select",
          "tooltip": "Select the reranker model. Smaller models are faster; larger models may improve ranking quality."
        },
        {
          "key": "flashrank_blend_weight",
          "label": "Blend Weight (rerank vs hybrid)",
          "value": 0.0,
          "options": null,
          "min": 0.0,
          "max": 1.0,
          "step": 0.05,
          "type": "slider",
          "tooltip": "0.0 = pure reranker order; 1.0 = pure hybrid order; values in-between blend both."
        },
        {
          "key": "flashrank_max_candidates",
          "label": "Max Candidates",
          "value": 100,
          "options": null,
          "min": 10.0,
          "max": 500.0,
          "step": 10.0,
          "type": "slider",
          "tooltip": "Upper bound on how many candidates to send to the reranker. Actual cap also depends on dynamic sizing from top_k."
        },
        {
          "key": "flashrank_batch_size",
          "label": "Reranker Batch Size",
          "value": 32,
          "options": null,
          "min": 8.0,
          "max": 128.0,
          "step": 8.0,
          "type": "slider",
          "tooltip": "Batch size for reranker calls where applicable. Larger batches can improve throughput but use more memory."
        }
      ]
    },
    {
      "key": "query_analysis",
      "label": "Query Analysis",
      "description": "Intelligent query routing and expansion to optimize retrieval strategy.",
      "llm_override_enabled": false,
      "llm_override_value": null,
      "parameters": [
        {
          "key": "enable_query_expansion",
          "label": "Enable Query Expansion",
          "value": false,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "When results are sparse, automatically generate synonyms and related terms to expand the query and improve recall. Uses LLM for term generation."
        },
        {
          "key": "query_expansion_threshold",
          "label": "Expansion Threshold",
          "value": 3,
          "options": null,
          "min": 1.0,
          "max": 10.0,
          "step": 1.0,
          "type": "slider",
          "tooltip": "Trigger query expansion when initial retrieval returns fewer than this many results. Lower values expand more aggressively."
        }
      ]
    },
    {
      "key": "pdf_processing",
      "label": "PDF Processing",
      "description": "Controls how PDF documents are converted to text",
      "llm_override_enabled": true,
      "llm_override_value": null,
      "parameters": [
        {
          "key": "use_marker_for_pdf",
          "label": "Use Marker for PDF",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Enable Marker for advanced PDF conversion to Markdown. Provides superior quality for complex PDFs with tables, equations, and multi-column layouts. Processing takes 2-5x longer than standard extraction."
        },
        {
          "key": "marker_output_format",
          "label": "Marker Output Format",
          "value": "markdown",
          "options": [
            "markdown",
            "json",
            "html",
            "chunks"
          ],
          "min": null,
          "max": null,
          "step": null,
          "type": "select",
          "tooltip": "Controls Marker's output format. Markdown is recommended for RAG ingestion as it preserves structure for chunking."
        },
        {
          "key": "marker_use_llm",
          "label": "Marker Use LLM Processors",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Enable LLM-powered hybrid processors for complex regions like tables, equations, and diagrams. Significantly improves extraction quality but increases processing time."
        },
        {
          "key": "marker_paginate_output",
          "label": "Marker Paginate Output",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Include page number markers in Marker output for document provenance tracking. Enables citations back to original page numbers."
        },
        {
          "key": "marker_force_ocr",
          "label": "Marker Force OCR",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Force OCR processing on all PDF pages. Use for PDFs with garbled or problematic embedded text. Processing is 10-20x slower than standard extraction."
        },
        {
          "key": "marker_strip_existing_ocr",
          "label": "Marker Strip Existing OCR",
          "value": false,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Strip embedded OCR text and re-OCR with Marker. Use when existing OCR quality is poor, common in low-quality scans."
        },
        {
          "key": "marker_pdftext_workers",
          "label": "Marker PDF Text Workers",
          "value": 4,
          "options": null,
          "min": 1.0,
          "max": 16.0,
          "step": 1.0,
          "type": "slider",
          "tooltip": "Number of parallel workers for PDF text extraction. More workers increase processing speed but use more CPU and memory."
        },
        {
          "key": "marker_llm_model",
          "label": "Marker LLM Model",
          "value": "gpt-4o-mini",
          "options": [
            "gpt-4o-mini",
            "gpt-4o",
            "gpt-4-turbo",
            "claude-3-5-sonnet-20241022"
          ],
          "min": null,
          "max": null,
          "step": null,
          "type": "select",
          "tooltip": "LLM model used by Marker for table extraction and complex layout analysis when 'Marker Use LLM' is enabled. API key must be configured in OPENAI_API_KEY or MARKER_LLM_API_KEY environment variable."
        }
      ]
    },
    {
      "key": "entity_extraction",
      "label": "Entity Extraction",
      "description": "Controls how entities and relationships are extracted from text",
      "llm_override_enabled": true,
      "llm_override_value": null,
      "parameters": [
        {
          "key": "enable_entity_extraction",
          "label": "Enable Entity Extraction",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Master toggle to enable entity and relationship extraction from documents. Creates entity nodes in the knowledge graph and enables entity-aware retrieval."
        },
        {
          "key": "enable_gleaning",
          "label": "Enable Gleaning",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Enable multi-pass entity extraction with conversation history. Improves entity quality by allowing the LLM to refine extractions across multiple passes."
        },
        {
          "key": "max_gleanings",
          "label": "Max Gleaning Passes",
          "value": 1,
          "options": null,
          "min": 0.0,
          "max": 5.0,
          "step": 1.0,
          "type": "slider",
          "tooltip": "Number of additional gleaning passes after initial extraction. 0 disables gleaning, 1 is recommended for most documents, 2 for high-value technical content."
        },
        {
          "key": "entity_extraction_format",
          "label": "Entity Extraction Format",
          "value": "tuple_v1",
            "options": [
              "tuple_v1"
            ],
          "min": null,
          "max": null,
          "step": null,
          "type": "select",
          "tooltip": "Entity extraction output format. Tuple format provides robust extraction and token efficiency."
        },
        {
          "key": "tuple_format_validation",
          "label": "Tuple Format Validation",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Enable strict validation of tuple format output structure and field requirements. Recommended for production to ensure data quality."
        },
        
        {
          "key": "tuple_max_description_length",
          "label": "Tuple Max Description Length",
          "value": 500,
          "options": null,
          "min": 100.0,
          "max": 2000.0,
          "step": 50.0,
          "type": "slider",
          "tooltip": "Maximum character length for entity and relationship descriptions. Prevents token bloat while maintaining sufficient context."
        }
      ]
    },
    {
      "key": "description_enhancement",
      "label": "Description Enhancement",
      "description": "LLM-powered summarization of entity descriptions",
      "llm_override_enabled": true,
      "llm_override_value": null,
      "parameters": [
        {
          "key": "enable_description_summarization",
          "label": "Enable Description Summarization",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Enable LLM-based summarization of accumulated entity and relationship descriptions. Provides 50-70% compression and deduplicates repetitive information."
        },
        {
          "key": "summarization_min_mentions",
          "label": "Summarization Min Mentions",
          "value": 3,
          "options": null,
          "min": 1.0,
          "max": 10.0,
          "step": 1.0,
          "type": "slider",
          "tooltip": "Minimum mention count required to trigger summarization. Only descriptions mentioned N or more times are summarized, filtering low-value content."
        },
        {
          "key": "summarization_min_length",
          "label": "Summarization Min Length",
          "value": 200,
          "options": null,
          "min": 50.0,
          "max": 1000.0,
          "step": 50.0,
          "type": "slider",
          "tooltip": "Minimum character length to trigger summarization. Avoids summarizing already-concise text, saving processing time."
        },
        {
          "key": "summarization_batch_size",
          "label": "Summarization Batch Size",
          "value": 5,
          "options": null,
          "min": 1.0,
          "max": 20.0,
          "step": 1.0,
          "type": "slider",
          "tooltip": "Number of entities or relationships to summarize per LLM call. Larger batches reduce API calls but use more tokens per request."
        },
        {
          "key": "summarization_cache_enabled",
          "label": "Summarization Cache Enabled",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Enable SHA256-based caching to avoid re-summarizing identical descriptions. Reduces redundant LLM calls and processing time."
        }
      ]
    },
    {
      "key": "graph_persistence",
      "label": "Graph Persistence",
      "description": "Controls how entities are persisted to Neo4j",
      "llm_override_enabled": false,
      "llm_override_value": null,
      "parameters": [
        {
          "key": "enable_phase2_networkx",
          "label": "Enable Phase 2 NetworkX",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Enable NetworkX intermediate graph layer for batch persistence. Provides 5-10x faster ingestion through batch processing. Experimental feature."
        },
        {
          "key": "neo4j_unwind_batch_size",
          "label": "Neo4j UNWIND Batch Size",
          "value": 500,
          "options": null,
          "min": 100.0,
          "max": 1000.0,
          "step": 50.0,
          "type": "slider",
          "tooltip": "Maximum number of entities to persist per Neo4j UNWIND batch transaction. Larger batches reduce transaction overhead but use more memory."
        },
        {
          "key": "max_nodes_per_doc",
          "label": "Max Nodes Per Document",
          "value": 2000,
          "options": null,
          "min": 500.0,
          "max": 10000.0,
          "step": 100.0,
          "type": "number",
          "tooltip": "Maximum entity nodes allowed per document. Safety limit to prevent memory issues with very large documents."
        },
        {
          "key": "max_edges_per_doc",
          "label": "Max Edges Per Document",
          "value": 5000,
          "options": null,
          "min": 1000.0,
          "max": 20000.0,
          "step": 100.0,
          "type": "number",
          "tooltip": "Maximum relationship edges allowed per document. Safety limit for relationship count to prevent memory exhaustion."
        },
        {
          "key": "importance_score_threshold",
          "label": "Importance Score Threshold",
          "value": 0.3,
          "options": null,
          "min": 0.0,
          "max": 1.0,
          "step": 0.05,
          "type": "slider",
          "tooltip": "Minimum importance score to include entity in graph. Acts as quality filter, with lower values including more entities but potentially reducing quality."
        },
        {
          "key": "strength_threshold",
          "label": "Strength Threshold",
          "value": 0.4,
          "options": null,
          "min": 0.0,
          "max": 1.0,
          "step": 0.05,
          "type": "slider",
          "tooltip": "Minimum relationship strength to persist. Filters weak relationships, with lower values creating more connections but potentially adding noise."
        }
      ]
    },
    {
      "key": "ocr_processing",
      "label": "OCR & Image Processing",
      "description": "Extract text from images and scanned documents",
      "llm_override_enabled": false,
      "llm_override_value": null,
      "parameters": [
        {
          "key": "enable_ocr",
          "label": "Enable OCR",
          "value": true,
          "options": null,
          "min": null,
          "max": null,
          "step": null,
          "type": "toggle",
          "tooltip": "Enable OCR processing to extract text from embedded images in documents. Increases processing time by approximately 20-30% per document."
        },
        {
          "key": "ocr_quality_threshold",
          "label": "OCR Quality Threshold",
          "value": 0.6,
          "options": null,
          "min": 0.0,
          "max": 1.0,
          "step": 0.05,
          "type": "slider",
          "tooltip": "Minimum confidence score to accept OCR results. Higher values ensure better quality but may skip low-confidence text."
        }
      ]
    },
    {
      "key": "performance",
      "label": "Performance & Limits",
      "description": "Control API usage, concurrency, and resource limits",
      "llm_override_enabled": false,
      "llm_override_value": null,
      "parameters": [
        {
          "key": "llm_concurrency",
          "label": "LLM Concurrency",
          "value": 2,
          "options": null,
          "min": 1.0,
          "max": 20.0,
          "step": 1.0,
          "type": "slider",
          "tooltip": "Maximum number of concurrent LLM API requests during ingestion. Higher values speed up processing but may hit rate limits."
        },
        {
          "key": "embedding_concurrency",
          "label": "Embedding Concurrency",
          "value": 3,
          "options": null,
          "min": 1.0,
          "max": 50.0,
          "step": 1.0,
          "type": "slider",
          "tooltip": "Maximum number of concurrent embedding API requests during ingestion. Higher values speed up processing but may hit rate limits."
        },
        {
          "key": "llm_delay_min",
          "label": "LLM Delay Min (seconds)",
          "value": 0.5,
          "options": null,
          "min": 0.0,
          "max": 5.0,
          "step": 0.1,
          "type": "slider",
          "tooltip": "Minimum delay in seconds between LLM API requests. Helps avoid rate limiting with exponential backoff."
        },
        {
          "key": "llm_delay_max",
          "label": "LLM Delay Max (seconds)",
          "value": 1,
          "options": null,
          "min": 0.0,
          "max": 10.0,
          "step": 0.5,
          "type": "slider",
          "tooltip": "Maximum delay in seconds between LLM API requests during exponential backoff. Caps retry delays."
        },
        {
          "key": "embedding_delay_min",
          "label": "Embedding Delay Min (seconds)",
          "value": 0.5,
          "options": null,
          "min": 0.0,
          "max": 5.0,
          "step": 0.1,
          "type": "slider",
          "tooltip": "Minimum delay in seconds between embedding API requests. Helps avoid rate limiting with exponential backoff."
        },
        {
          "key": "embedding_delay_max",
          "label": "Embedding Delay Max (seconds)",
          "value": 1,
          "options": null,
          "min": 0.0,
          "max": 10.0,
          "step": 0.5,
          "type": "slider",
          "tooltip": "Maximum delay in seconds between embedding API requests during exponential backoff. Caps retry delays."
        }
      ]
    }
  ]
}