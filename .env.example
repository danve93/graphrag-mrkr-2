# Environment Configuration Template
# Copy this file to .env and update with your actual values

# LLM / Ollama Configuration
# Set provider to 'ollama' to use a local Ollama server for embeddings and LLM
# Supported values: 'openai' (default) or 'ollama'
LLM_PROVIDER=openai

# OpenAI API Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_BASE_URL=https://api.openai.com/v1/
OPENAI_MODEL=gpt-4o-mini
OPENAI_PROXY=

# Neo4j Configuration
# Use bolt://neo4j:7687 for Docker Compose, bolt://localhost:7687 for local Python scripts
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_neo4j_password_here
NEO4J_AUTH=NEO4J_USERNAME/NEO4J_PASSWORD
# Optional Docker Compose credential shortcut: set NEO4J_AUTH to '<user>/<password>'
# If set, docker-compose will use NEO4J_AUTH (e.g. NEO4J_AUTH=neo4j/test). When running
# the backend/service locally outside Compose, keep NEO4J_USERNAME/NEO4J_PASSWORD set for the
# application to read.
# Example for local demo (DO NOT USE in CI or public repos):
# NEO4J_AUTH=neo4j/test  # short/demo password; prefer generating a secure password or set NEO4J_USERNAME/NEO4J_PASSWORD

# If using Ollama, set the base URL (e.g. http://host.docker.internal:11434 or http://ollama:11434)
#OLLAMA_BASE_URL=http://localhost:11434
#OLLAMA_MODEL=llama3.2
#OLLAMA_EMBEDDING_MODEL=nomic-embed-text
#OLLAMA_API_KEY=   # Not required for local Ollama server

# Embedding Configuration
EMBEDDING_MODEL=text-embedding-ada-002
EMBEDDING_CONCURRENCY=3

# Document Processing Configuration (Optimized for Company Docs)
CHUNK_SIZE=1200
CHUNK_OVERLAP=150

# Application Configuration
LOG_LEVEL=INFO
MAX_UPLOAD_SIZE=104857600

# Feature Flags (Optimized for Quality)
ENABLE_ENTITY_EXTRACTION=true
ENABLE_QUALITY_SCORING=true
ENABLE_DELETE_OPERATIONS=true
FLASHRANK_ENABLED=true
FLASHRANK_MODEL_NAME=ms-marco-TinyBERT-L-2-v2

# Microsoft GraphRAG Phases (Enabled for Quality)
ENABLE_GLEANING=true
MAX_GLEANINGS=1
ENABLE_PHASE2_NETWORKX=true
ENABLE_DESCRIPTION_SUMMARIZATION=true

# Marker PDF Conversion (Highest Accuracy)
USE_MARKER_FOR_PDF=true
MARKER_USE_LLM=true
MARKER_FORCE_OCR=true
MARKER_OUTPUT_FORMAT=markdown
MARKER_LLM_MODEL=gpt-4o-mini
# SECURITY: API keys must ONLY be set here in .env, never in JSON config or code
# Optional: Separate API key for Marker (defaults to OPENAI_API_KEY if not set)
# MARKER_LLM_API_KEY=your_openai_api_key_here
# Optional: Set MARKER_LLM_SERVICE to use different LLM service class
# MARKER_LLM_SERVICE=marker.services.openai.OpenAIService

# Caching Configuration
ENTITY_LABEL_CACHE_SIZE=5000
ENTITY_LABEL_CACHE_TTL=300
EMBEDDING_CACHE_SIZE=10000
RETRIEVAL_CACHE_SIZE=1000
RETRIEVAL_CACHE_TTL=60
NEO4J_MAX_CONNECTION_POOL_SIZE=50
ENABLE_CACHING=true

# Additional Marker options (advanced)
MARKER_PAGINATE_OUTPUT=true
MARKER_STRIP_EXISTING_OCR=false
MARKER_PDFTEXT_WORKERS=4

# Redis Configuration (optional, for background job processing)
# REDIS_URL=redis://localhost:6379/0
