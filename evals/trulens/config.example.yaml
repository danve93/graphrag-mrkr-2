# TruLens Continuous Monitoring Configuration
# Copy this file to config.yaml and customize

version: "0.1"

trulens:
  # Enable/disable TruLens monitoring
  # Set to true to activate (also requires ENABLE_TRULENS_MONITORING=1 env var)
  enabled: false

  # Sampling rate for monitoring (0.0 to 1.0)
  # 1.0 = monitor all requests (recommended for dev/staging)
  # 0.1 = monitor 10% of requests (reduce cost in high-traffic production)
  sampling_rate: 1.0

  # Database configuration
  database:
    # Backend type: "postgresql" (recommended) or "sqlite" (dev/CI fallback)
    backend: "postgresql"

    # PostgreSQL configuration (production)
    postgresql:
      host: "${TRULENS_DB_HOST:-postgres-trulens}"
      port: 5432
      database: "${TRULENS_DB_NAME:-trulens}"
      user: "${TRULENS_DB_USER:-postgres}"
      password: "${TRULENS_DB_PASSWORD}"
      # Connection pool settings
      pool_size: 5
      max_overflow: 10
      pool_timeout: 30

    # SQLite configuration (development fallback)
    sqlite:
      path: "evals/trulens/trulens.db"

# Feedback function configuration
feedback:
  # LLM provider for feedback evaluation
  # Reuses existing llm_manager configuration (OpenAI by default)
  provider: "openai"

  # Feedback functions to enable
  functions:
    - answer_relevance        # Does answer address the query?
    - context_relevance       # Are retrieved chunks relevant?
    - groundedness            # Is answer faithful to context?
    - graph_reasoning_quality # Custom: Graph enrichment quality
    - latency_check           # Custom: Latency threshold check

  # Quality thresholds for alerting
  thresholds:
    answer_relevance_min: 0.7   # Alert if below 70%
    groundedness_min: 0.8        # Alert if below 80%
    context_relevance_min: 0.6   # Alert if below 60%
    latency_max_ms: 5000         # Alert if above 5 seconds

  # Model configuration for feedback evaluation
  model:
    temperature: 0.0  # Deterministic feedback
    max_tokens: 512

# TruLens Streamlit dashboard
dashboard:
  host: "localhost"
  port: 8501
  # Auto-open browser on launch
  open_browser: false

# Observability and metrics
observability:
  # Prometheus metrics endpoint
  prometheus:
    enabled: true
    # Metrics are exposed via main FastAPI app
    port: 8000
    path: "/api/trulens/metrics"
    # Metric aggregation window (seconds)
    aggregation_window: 300  # 5 minutes

  # Grafana dashboard provisioning (optional)
  grafana:
    enabled: false
    api_url: "http://localhost:3000"
    # Auto-import dashboard on startup
    auto_import: false

  # OpenTelemetry integration (future)
  opentelemetry:
    enabled: false
    # OTLP endpoint for traces
    # endpoint: "http://localhost:4317"

# Export configuration
export:
  enabled: true
  output_dir: "reports/trulens"
  formats:
    - json       # Programmatic access
    - csv        # Spreadsheet analysis
    - markdown   # Human-readable reports

# Integration with existing quality_monitor
integration:
  # Emit TruLens scores to quality_monitor for unified alerting
  emit_to_quality_monitor: false

# Logging configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  # Log TruLens operations to separate file
  file: "evals/trulens/trulens.log"
  # Rotate logs
  max_bytes: 10485760  # 10MB
  backup_count: 5
